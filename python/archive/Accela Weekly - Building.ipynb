{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:48:22.501305Z",
     "start_time": "2020-04-27T18:48:21.991665Z"
    },
    "code_folding": [
     19,
     40
    ]
   },
   "outputs": [],
   "source": [
    "#standard packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from labellines import labelLine, labelLines\n",
    "\n",
    "#administrative packages\n",
    "import os\n",
    "import operator\n",
    "import datetime\n",
    "mydate = datetime.datetime.now()\n",
    "from datetime import date,timedelta\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "planner_initials = {'ABC': 'Alan Carreon',\n",
    "                     'AS': 'Ana Spinola',\n",
    "                     'AMS': 'Andrew Smith',\n",
    "                     'CG': 'Chip Griffin',\n",
    "                     'EB': 'Ethan T Bindernagel',\n",
    "                     'GDK': 'Greg Kapovich',\n",
    "                     'GV': 'Gerardo Victoria',\n",
    "                     'HEC': 'Haley E Croffoot',\n",
    "                     'HH': 'Haley Hubbard',\n",
    "                     'JG': 'Jessica J Gonzalez',\n",
    "                     'JCav': 'Jeanine Cavalli',\n",
    "                     'KN': 'Ken Nodder',\n",
    "                     'OA': 'Ozzy Arce',\n",
    "                     'SKG': 'Simar Gill',\n",
    "                     'SP': 'Sukhamrit S Purewal',\n",
    "                     'TC': 'Trishia Caguiat'}\n",
    "planner_names = {v:k for k,v in planner_initials.items()}\n",
    "planner_names['Haley Hubbard'] = 'HEC'\n",
    "planner_initials['HH'] = 'Haley E Croffoot'\n",
    "Complete_Closed = ['Approved - Closed', 'Closed', 'Not Approved - Closed']\n",
    "Planner_Closed = ['Close Out', 'Approved', 'Not Approved']\n",
    "Ent = {\n",
    " 'Zoning Amendment': 'Amend',\n",
    " 'Use Permit Minor': 'MUP',\n",
    " 'Design Review': 'DR',\n",
    " 'Design Review Oversized Home': 'DR',\n",
    " 'Design Review Other': 'DR',\n",
    " 'Design Review Commercial': 'DR',\n",
    " 'General Plan Amendment': 'Amend',\n",
    " 'Design Review Antenna': 'DR',\n",
    " 'Design Review Residential': 'DR',\n",
    " 'Use Permit Conditional': 'CUP',\n",
    " 'Use Permit Administrative': 'AUP',\n",
    " 'ZCL':'ZCL',\n",
    " 'Variance': 'Vari',\n",
    " 'Rezoning': 'ReZone',\n",
    " 'Tree Dripline Encroachment': 'Tree',\n",
    " 'Tree Removal Permit': 'Tree',\n",
    " '': 'Other',\n",
    " 'Other': 'Other',\n",
    " 'Tentative Map Major Subdivision': 'Maj Sub',\n",
    " 'Drip Line Encroachment': 'Other',\n",
    " 'Tentative Map Minor Subdivision': 'Min Sub',\n",
    " 'Tentative Map Condo Conversion': 'Conv',\n",
    " 'Hillside Performance Standards': 'Other'}\n",
    "Ent_names = {v:k for k,v in Ent.items()}\n",
    "Ent_names['Other'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T17:38:36.682856Z",
     "start_time": "2020-04-27T17:38:36.619027Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T17:38:36.683854Z",
     "start_time": "2020-04-27T17:38:36.101Z"
    }
   },
   "source": [
    "path = r'C:\\Users\\nelms\\Downloads\\BlueTest_Engineering_SDP (3).csv'\n",
    "SDP = pd.read_csv(path, skiprows=1)\n",
    "\n",
    "date_fields = ['Open Date', 'Status Date']\n",
    "for d in date_fields:\n",
    "    SDP[d] = SDP[d].apply(lambda s: pd.to_datetime(s, infer_datetime_format=True))\n",
    "    \n",
    "SDP = SDP[[\n",
    "    'Permit #',\n",
    "    'Record Status',\n",
    "    'Open Date',\n",
    "    'Status Date',\n",
    "    'Project Type',\n",
    "    'UPDATED BY',\n",
    "    'Description'\n",
    "    ]].drop_duplicates(keep='last').set_index('Permit #')\n",
    "SDP.loc[SDP['UPDATED BY']=='AA CONV', 'UPDATED BY'] = ''\n",
    "sdp_t = {\n",
    "    'Subdivision':'Subdivision', \n",
    "    'COMM':'Commercial',\n",
    "    'RES':'Residential', \n",
    "    'Residential':'Residential',\n",
    "    'Commercial':'Commercial'\n",
    "    }\n",
    "SDP['Project Type'] = SDP['Project Type'].map(sdp_t)\n",
    "\n",
    "WS = SDP\n",
    "\n",
    "def colnum_string(n):\n",
    "    string = \"\"\n",
    "    n = n + 1\n",
    "    while n > 0:\n",
    "        n, remainder = divmod(n - 1, 26)\n",
    "        string = chr(65 + remainder) + string\n",
    "    return string\n",
    "\n",
    "def rng_create(A, one, B, two):\n",
    "    return str(colnum_string(A)) + str(one) + \":\" + str(colnum_string(B)) + str(two)\n",
    "\n",
    "def get_col_widths(dataframe):\n",
    "    # First we find the maximum length of the index column   \n",
    "    idx_max = max([len(str(s)) for s in dataframe.index.values] + [len(str(dataframe.index.name))])\n",
    "    # Then, we concatenate this to the max of the lengths of column name and its values for each column, left to right\n",
    "    return [idx_max] + [max([len(str(s)) for s in dataframe[col].values] + [len(col)]) for col in dataframe.columns]\n",
    "\n",
    "def normalize_types(lyr):\n",
    "        str_list = list(lyr.select_dtypes(include=['datetime','period[Q-DEC]','O']))\n",
    "        convert_dict = {s:str for s in str_list}\n",
    "        no_str = [l for l in list(lyr) if l not in str_list]\n",
    "        no_dict = lyr[no_str].dtypes.to_dict()\n",
    "        convert_dict.update(no_dict)\n",
    "        return lyr.astype(convert_dict)\n",
    "\n",
    "new_file = 'SDP_Status.xlsx'\n",
    "folder = r'O:\\CDD\\PLANNING\\AN\\Projects\\Accela Reporting'\n",
    "\n",
    "import xlsxwriter as xlsx\n",
    "wrkbk = xlsx.Workbook(os.path.join(folder, new_file))\n",
    "\n",
    "for tbl, name, caption in [(WS, 'Permits', 'SDPs with status in 2018 to 2020')]:\n",
    "    worksheet = wrkbk.add_worksheet(name)\n",
    "    \n",
    "    lyr = tbl.copy()\n",
    "    \n",
    "    lyr = normalize_types(lyr)\n",
    "    \n",
    "    header = np.array([[lyr.index.name] + list(lyr)])\n",
    "    data = lyr.reset_index().to_numpy()\n",
    "    if data.shape[1] != header.shape[1]:        \n",
    "        dif = data.shape[1] - header.shape[1]\n",
    "        fix_head = [lyr.index.name] + list(lyr)\n",
    "        for r in range(dif):\n",
    "            fix_head = [' '] + fix_head\n",
    "        header = np.array([fix_head])\n",
    "    table = np.vstack((header,data))\n",
    "    numRows,numColumns = table.shape\n",
    "    \n",
    "    cols = [{'header':h} for h in header[0]]\n",
    "    \n",
    "    rowoffset,coloffset = 1,0\n",
    "    \n",
    "    if len(caption) > 0:\n",
    "        cell_format = wrkbk.add_format()\n",
    "        cell_format.set_bold() \n",
    "        worksheet.merge_range('A1:B1', caption, cell_format)\n",
    "        rowoffset += 1\n",
    "    \n",
    "    length,width = data.shape\n",
    "    table_range = rng_create(0+coloffset, 0+rowoffset, width-1+coloffset, length+rowoffset)\n",
    "    \n",
    "    worksheet.add_table(table_range, {'data': data,\n",
    "                                      'style': 'Table Style Light 1',\n",
    "                                       'columns': cols\n",
    "                                 })\n",
    "    for e,c in enumerate(get_col_widths(lyr)):\n",
    "        e = e+coloffset\n",
    "        cw = colnum_string(e)\n",
    "        cw = cw + ':' + cw\n",
    "        if c > 30:\n",
    "            c = 30\n",
    "        worksheet.set_column(cw, c+1)\n",
    "    \n",
    "wrkbk.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:29:15.402869Z",
     "start_time": "2020-04-27T19:29:15.370951Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Location of CSV from Accela Ad Hoc\n",
    "path = r'O:\\CDD\\PLANNING\\AN\\Projects\\Accela Reporting\\Building\\Weekly_Status_BuildCheck.csv'\n",
    "WS = pd.read_csv(path).set_index('RECORD ID')\n",
    "WS.index.name = 'Record ID'\n",
    "\n",
    "WS.rename(columns={\n",
    "    'ACTION BY NAME FML#':'Intaker', \n",
    "    'ASSIGNED NAME FML#':'Engineer', \n",
    "    'RECORD OPEN DATE':'Open Date', \n",
    "    'DATE ASSIGNED':'Date Assigned',\n",
    "    'DESCRIPTION':'Description'\n",
    "}, inplace=True)\n",
    "Admin_fields = ['Address', 'Description', 'Intaker']\n",
    "Date_fields = ['Open Date', 'Date Assigned']\n",
    "PCE_fields = ['Engineer']\n",
    "\n",
    "WS.dropna(subset=['Intaker', 'Engineer'], inplace=True)\n",
    "# ADMIN\n",
    "# Initials\n",
    "#WS['Intaker'] = WS['Intaker'].apply(lambda x: ''.join([n[0] for n in x.split()]))\n",
    "# Last Name\n",
    "WS['Intaker'] = WS['Intaker'].apply(lambda x: x.split()[-1])\n",
    "# descript\n",
    "def adds(add):\n",
    "    add = add.replace(\"(N) \",\"\").replace(\"T.I.\",\"TI\").strip()\n",
    "    for sep in [\";\", \",\", \" (\", \"-\", \" &\", \" TO \"]:\n",
    "        if sep in add:\n",
    "            add = add.split(sep)[0].strip()\n",
    "    add = \" \".join(add.split()).replace('\"','')\n",
    "    while len(add) > 30:\n",
    "        for sep in [\" AND \"]:\n",
    "            add = add.split(sep)[0].strip()\n",
    "        add = \" \".join(add.split()[:-1])\n",
    "    return add\n",
    "WS['Description'] = WS['Description'].apply(lambda x: adds(x))\n",
    "# Address\n",
    "WS['Address'] = WS['STREET NBR'].astype(str) + ' ' + WS['STREET NAME']\n",
    "WS['Address'] = WS['Address'].apply(lambda x: str(x).title().strip())\n",
    "\n",
    "# DATES\n",
    "WS.loc[WS['Date Assigned'].isna(), 'Date Assigned'] = WS.loc[WS['Date Assigned'].isna(), 'DATE STATUS']\n",
    "for d in Date_fields:\n",
    "    WS[d] = WS[d].apply(lambda x: pd.to_datetime(x, format=\"%m/%d/%Y\"))\n",
    "\n",
    "WS = WS[Admin_fields + Date_fields + PCE_fields].sort_values(by=['Record ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:33:20.684124Z",
     "start_time": "2020-04-27T19:33:20.617197Z"
    },
    "code_folding": [
     33
    ]
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def colnum_string(n):\n",
    "    string = \"\"\n",
    "    n = n + 1\n",
    "    while n > 0:\n",
    "        n, remainder = divmod(n - 1, 26)\n",
    "        string = chr(65 + remainder) + string\n",
    "    return string\n",
    "\n",
    "def rng_create(A, one, B, two):\n",
    "    return str(colnum_string(A)) + str(one) + \":\" + str(colnum_string(B)) + str(two)\n",
    "\n",
    "def get_col_widths(dataframe):\n",
    "    # First we find the maximum length of the index column   \n",
    "    idx_max = max([len(str(s)) for s in dataframe.index.values] + [len(str(dataframe.index.name))])\n",
    "    # Then, we concatenate this to the max of the lengths of column name and its values for each column, left to right\n",
    "    return [idx_max] + [max([len(str(s)) for s in dataframe[col].values] + [len(col)]) for col in dataframe.columns]\n",
    "\n",
    "def normalize_types(lyr):\n",
    "        str_list = list(lyr.select_dtypes(include=['datetime','period[Q-DEC]','O']))\n",
    "        convert_dict = {s:str for s in str_list}\n",
    "        no_str = [l for l in list(lyr) if l not in str_list]\n",
    "        no_dict = lyr[no_str].dtypes.to_dict()\n",
    "        convert_dict.update(no_dict)\n",
    "        return lyr.astype(convert_dict)\n",
    "\n",
    "new_file = 'PCE_Status.xlsx'\n",
    "folder = r'O:\\CDD\\PLANNING\\AN\\Projects\\Accela Reporting\\Weekly_Building'\n",
    "\n",
    "import xlsxwriter as xlsx\n",
    "wrkbk = xlsx.Workbook(os.path.join(folder, new_file))\n",
    "\"\"\"\n",
    "for OG, name in [(WS, 'Permits')]:\n",
    "    worksheet = wrkbk.add_worksheet(name)\n",
    "    \n",
    "    lyr = OG.copy()\n",
    "    \n",
    "    lyr = normalize_types(lyr)\n",
    "    \n",
    "    header = np.array([[lyr.index.name] + list(lyr)])\n",
    "    data = lyr.reset_index().to_numpy()\n",
    "    if data.shape[1] != header.shape[1]:        \n",
    "        dif = data.shape[1] - header.shape[1]\n",
    "        fix_head = [lyr.index.name] + list(lyr)\n",
    "        for r in range(dif):\n",
    "            fix_head = [' '] + fix_head\n",
    "        header = np.array([fix_head])\n",
    "    table = np.vstack((header,data))\n",
    "    numRows,numColumns = table.shape\n",
    "    \n",
    "    idx = [0]\n",
    "    if type(lyr.index) == pd.MultiIndex:\n",
    "        idx.append(1)\n",
    "        table[0,0:2] = list(lyr.index.names)\n",
    "    else:\n",
    "        table[0,0:1] = list(lyr.index.names)\n",
    "\n",
    "    for c in range(numColumns):\n",
    "        for r in range(numRows):\n",
    "            format_dict = {'font_name':'Arial'}\n",
    "            \n",
    "            # TOP\n",
    "            if (r == 0) & (c not in idx):\n",
    "                format_dict['bottom'] = 2\n",
    "                format_dict['bold'] = True\n",
    "                format_dict['text_wrap'] = True\n",
    "            # INDEX NAME\n",
    "            if (r == 0) & (c in idx):\n",
    "                format_dict['italic'] = True\n",
    "            # RIGHT\n",
    "            elif (r != 0) & (c == range(numColumns)[-1]):\n",
    "                format_dict['right'] = 2\n",
    "                if (r == range(numRows)[-1]):\n",
    "                    format_dict['bottom'] = 2\n",
    "            # LEFT\n",
    "            elif (r != 0) & (c in idx):\n",
    "                format_dict['bold'] = True\n",
    "                if (1 not in idx)or(c == 1):\n",
    "                    format_dict['right'] = 2\n",
    "            # BOTTOM\n",
    "            elif (r == range(numRows)[-1]) & (c not in idx):\n",
    "                format_dict['bottom'] = 2\n",
    "                if (c == range(numColumns)[-1]):\n",
    "                    format_dict['right'] = 2\n",
    "            item = table[r][c]\n",
    "            \n",
    "            cell_format = wrkbk.add_format(format_dict)\n",
    "            worksheet.write(r, c, item, cell_format)\n",
    "        if c not in idx:\n",
    "            worksheet.set_column(c, c, 10)\n",
    "        else:\n",
    "            try:\n",
    "                worksheet.set_column(c, c, len(max(table[:,c], key=len))+1)\n",
    "            except:\n",
    "                print(table[:,c])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_date_range(series, form='%m/%d/%Y'):\n",
    "    dates = [pd.to_datetime(s, infer_datetime_format=True) for s in series.values]\n",
    "    max_d = max(dates).strftime(form)\n",
    "    min_d = min(dates).strftime(form)\n",
    "    return min_d, max_d\n",
    "WSmn, WSmx = get_date_range(WS['Date Assigned'])\n",
    "\n",
    "for tbl, name, caption in [(WS, 'PCE', 'Plan Checks from {} to {}'.format(WSmn, WSmx))]:\n",
    "    worksheet = wrkbk.add_worksheet(name)\n",
    "    \n",
    "    lyr = tbl.copy()\n",
    "    \n",
    "    lyr = normalize_types(lyr)\n",
    "    \n",
    "    header = np.array([[lyr.index.name] + list(lyr)])\n",
    "    data = lyr.reset_index().to_numpy()\n",
    "    if data.shape[1] != header.shape[1]:        \n",
    "        dif = data.shape[1] - header.shape[1]\n",
    "        fix_head = [lyr.index.name] + list(lyr)\n",
    "        for r in range(dif):\n",
    "            fix_head = [' '] + fix_head\n",
    "        header = np.array([fix_head])\n",
    "    table = np.vstack((header,data))\n",
    "    numRows,numColumns = table.shape\n",
    "    \n",
    "    cols = [{'header':h} for h in header[0]]\n",
    "    \n",
    "    rowoffset,coloffset = 1,0\n",
    "    \n",
    "    if len(caption) > 0:\n",
    "        cell_format = wrkbk.add_format()\n",
    "        cell_format.set_bold() \n",
    "        worksheet.merge_range('A1:B1', caption, cell_format)\n",
    "        worksheet.write('D1', 'updated on {}'.format(datetime.now().strftime('%m-%d-%Y')))\n",
    "        rowoffset += 1\n",
    "    \n",
    "    length,width = data.shape\n",
    "    table_range = rng_create(0+coloffset, 0+rowoffset, width-1+coloffset, length+rowoffset)\n",
    "    \n",
    "    worksheet.add_table(table_range, {'data': data,\n",
    "                                      'style': 'Table Style Light 1',\n",
    "                                       'columns': cols\n",
    "                                 })\n",
    "    for e,c in enumerate(get_col_widths(lyr)):\n",
    "        e = e+coloffset\n",
    "        cw = colnum_string(e)\n",
    "        cw = cw + ':' + cw\n",
    "        if c > 30:\n",
    "            c = 30\n",
    "        worksheet.set_column(cw, c+1)\n",
    "    \n",
    "wrkbk.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
